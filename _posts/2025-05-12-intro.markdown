---
layout: post
title:  "Introduction"
date:   2025-05-02 01:23:45 -0400
categories: Ethics
---

![image](it304teamsite/assets/images/intro1.png) <br />
Artificial Intelligence (AI) encompasses technologies that enable machines to perform tasks traditionally associated with human intelligence, such as recognizing speech, generating images, and making decisions. One of the most transformative advancements in this field is generative AI, which allows systems to produce original content—ranging from text and audio to images and video—by learning patterns from vast datasets. Technologies such as ChatGPT, DALL·E, and other large language and diffusion models are key examples of this shift.
The pace at which generative AI is evolving presents both vast potential and growing concern. As noted by JPMorgan Chase & Co. (2024), generative AI is expected to redefine entire industries by enhancing productivity, reducing operational costs, and driving innovation. At the same time, its capacity to create convincing synthetic media raises urgent questions around authenticity, trust, and social harm. With applications ranging from voice cloning to automated video generation, these tools challenge conventional understandings of authorship, privacy, and truth.
We chose to focus on generative AI because of its immediate and far-reaching implications for society and governance. For policymakers, the stakes are particularly high. Generative AI is not only accelerating change in the private sector, but it is also influencing public discourse, labor markets, and information integrity. Qualcomm (2024) highlights a timeline of rapid breakthroughs that demonstrate just how quickly these technologies are evolving—from the launch of GPT models to real-time voice replication tools. This accelerated development outpaces current policy responses, revealing the urgent need for regulatory frameworks that can keep pace with innovation.
Understanding generative AI is critical for crafting informed, ethical, and forward-looking policies. The technology's capacity to empower as well as disrupt makes it one of the defining challenges of our time.
Throughout history, Artificial Intelligence(AI) has been defined in various ways, focusing on its features and technological advancements. Kurzweil (1990) mentioned that AI is the art of creating machines that perform functions that require intelligence when performed by people, whereas Nilsson (1998) noted that AI is concerned with intelligent behavior in artifacts. These different approaches were differentiated as one group believed AI is a system that acts like a human. In contrast, another group believed AI is a system that combines both mathematics and engineering(Russell, S., & Norvig, P., 2003). However, today, we can see that both perspectives have been integrated to discover new AI-based technical advancements called Generative AI. Generative AI is an AI system that learns patterns from large datasets and creates an original output based on the learning. The primary applications of generative AI are AI image generation technology, such as Dall-E, Midjourney, and AI voice-replication technology, such as Resemble.AI and VocaliD. These real-world applications depict how AI continued to evolve into a powerful tool – both a boon and a curse, in reshaping human creativity and intelligence. 

![image](it304teamsite/assets/images/intro2.png) <br />
AI image-generating models such as Dall-E and Midjourney create a realistic image using a text prompt. For example, if I instructed the tool by writing something like this, “An advanced architectural design of a modern house on top of a hill with an astonishing view,” then the realistic image with such keen details is provided. This advanced tool is beneficial when bringing highly creative and complex concepts to life, which could have taken days or weeks for an individual to make; however, the application also endures a few complexities and social challenges.

Loss of human expression and emotional depth—There’s an argument on the internet over how AI tools could negatively impact creative fields. An article by Aoki Studio, which reflects on a similar discussion, highlights that the art is fundamentally known to be an expression of human experience. Some forms of art, such as painting, graphic design, and product design, express their emotions or thoughts, their feelings, or some kind of message through their art; however, the images created by AI models miss that touch of human emotions and expressive richness. For example, the famous prehistoric Lascaux cave paintings in France depicted human life around 17,000 years ago. In contrast, the famous black and white painting “Guernica” by Picasso still gives chills to the viewers as it symbolizes the terror and horror of war.

<p align="center">Copyright/plagiarism</p>
An online campaign, #NoToAIArt, was seen over the internet as many artists expressed concerns about the legality of AI image generators. To create images from text prompts in tools like Midjourney and Dall-E, the AI generators must rely on a large database of existing art and illustrations from various artists who shared their work on the internet. As AI is a system that learns patterns from large datasets and creates output based on its learning, the realistic images created by various AI generators as of today, are all inspired by the original artists however the organizations that made these tools deny that they pirated intellectual property of countless artists even though many artists claim that those large datasets often include a lot of copyrighted images(Shaffi, 2023).

Loss of integrity in the overall business—Woeller (2024) mentioned in her article on GoImagine that the use of AI-generated images in selling platforms or any commercial platforms without proper permissions and proper disclosure that this art was created by AI could potentially lead to accusations of copyright infringement and damage your business’s reputation and customers' trust. 

Similarly, an AI-voice replication technology, also known as voice cloning, is an AI simulation capable of generating synthetic speech that resembles a targeted human voice. Technological advancements have made it difficult to differentiate between a real human voice and a fake automated voice. Such AI text-to-voice software has helped educational purposes by cloning the voices of historical figures for interactive teaching and realistic storytelling. IT has also helped narrate audiobooks and assist persons with speech disabilities; however, the applications have been noticed to be enduring a few complexities and social challenges(Martin,2022).

Audio Deepfakes—Due to rapid progress in voice cloning technology, audio deepfake cases are rising as criminals and hackers can communicate with their targets easily and anonymously and obtain their sensitive information(Lyons, 2020). Audio deepfakes are also used in pornography content to exploit their target’s image or defame them with poor intent. 

Social engineering and scams - Recently, some news has been spreading regarding phishing and social engineering attempts via voice cloning software. Attackers or hackers usually use such tools to talk to their target in a voice of someone they trust, create a scenario where the other person is in desperate need - could be financial, or could be sensitive informations like their bank number, credit card information, company’s information, and ultimately trick them into their scam. In a few cases, voice cloning has been used to bully online and create fake evidence in criminal cases(Martin,2022).

Job displacements - Companies such as Respeecher and Sonantic create hyper-realistic voices that sound almost similar to a real human voice. With the use of deep-learning algorithm in learning voice patterns, pitch, timbre, and mimicking accents, tone, and emotions, these tools could create high-accuracy, which led several companies to choose AI tools, which was comparatively budget friendly and less time consuming, to support their business rather than voice actors, which led to their potential job displacement(Karunakaran, 2024).


![image](it304teamsite/assets/images/intro3.png) <br />
Generative Artificial Intelligence’s ability to create, recreate, and replicate images, viewable media, and speech synthesis (synthetic media) poses significant risks as well as social and political concerns. Due to generative Artificial Intelligence being able to create deepfakes of and recreate the voices of other people through speech synthesis, it can lead to a much larger wide spread of misinformation and disinformation in all sectors, especially for politics and governments; lead to the loss of human led jobs, such as acting, advertising, etc.; and lead to bigger accounts of identity theft and misrepresentation of people. Furthermore, the technology’s ability to replicate and create synthetic media based on off what it was “trained” on poses the potential and possibility of challenging current ethics related to copyright and plagiarism laws.

The use of generative Artificial Intelligence has its own set of positives and negatives from an ethical standpoint. For example, the use of this technology to create synthetic media with the intent to spread harm is morally wrong as it can cause serious harm to a person’s self-image, reputation, position in society. But the use of the technology for synthetic media can be used to quickly send out important messages, such as a health warning for a new disease going around in country that the people should know about, or it can be used aid those with those with a vocal disability.

The use the technology to replace current jobs is another example that brings up the ethics of this technology in question.  Synthetic media has the ability to replace jobs in areas such as acting, filmmaking, advertising, and more. If companies start to use artificial intelligence as recommendation to create media, it is probable that they would replace the people hired to create media which leads to a loss in jobs and creativity. This replacement would undermine the amount of respect given to people in their positions by their employer and potentially cause widespread displacement of workers in those areas. However, if companies see it as a recommendation to assist and not replace the people creating media, the use of this technology could lead to the creation of new jobs, an increase and boost to productivity, and avoid worker displacement.

Regardless of its ethical concerns, Generative Artificial Intelligence is here to stay. Policy makers should strive to alleviate some of these ethical concerns in various ways. One recommendation to alleviate such concerns is making synthetic media transparent and explicit about how it was made or including some indication that it was made with the use of generative artificial intelligence.  A second recommendation would be to have synthetic media require consent from the people whose likeness or content is being used in the media itself or to train the AI. A third recommendation would be to increase public knowledge and recognition of synthetic media to combat the spread of disinformation in the general public. A fourth recommendation would be to create and strengthen worker rights and protections that help make it so that this technology helps assist work and create new jobs rather wholly replace the workers. A fifth and final recommendation would be to create more modern copyright laws that requires the consent of the original creators or people whose likeness is being used to create and train the AI,  provides them rights over how the AI can be used, and protects their work or likeness from being used in a harmful or devastating way.

hello
